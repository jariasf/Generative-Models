{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###Load MNIST images\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Samples: 55000. Feature Dimension: 784\n"
     ]
    }
   ],
   "source": [
    "n_samples = mnist.train.num_examples\n",
    "m_features = mnist.train.images.shape[1]\n",
    "print(\"Number of Samples: {}. Feature Dimension: {}\".format(n_samples, m_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x5280710>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x5259390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "##Data Visualization\n",
    "plt.imshow(np.reshape(-mnist.train.images[40], (28, 28)), interpolation='none',cmap=plt.get_cmap('gray'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'   \\n    def visualize_generation(self, x_sample):\\n        with tf.Session() as sess:\\n            x_reconstruct,z_vals,z_mean_val,z_log_sigma_sq_val = sess.run((self.generated,self.z, \\n                                                                           self.z_mean, self.z_sigma), \\n                                                                           feed_dict={self.x: x_sample})\\n\\n            plt.figure(figsize=(8, 12))\\n            for i in range(5):\\n                plt.subplot(5, 3, 3*i + 1)\\n                plt.imshow(x_sample[i].reshape(28, 28), vmin=0, vmax=1,  interpolation=\\'none\\',cmap=plt.get_cmap(\\'gray\\'))\\n                plt.title(\"Test input\")\\n\\n                #plt.colorbar()\\n                plt.subplot(5, 3, 3*i + 2)\\n                plt.scatter(z_vals[:,0],z_vals[:,1], c=\\'gray\\', alpha=0.5)\\n                plt.scatter(z_mean_val[i,0],z_mean_val[i,1], c=\\'green\\', s=64, alpha=0.5)\\n                plt.scatter(z_vals[i,0],z_vals[i,1], c=\\'blue\\', s=16, alpha=0.5)\\n\\n                plt.xlim((-3,3))\\n                plt.ylim((-3,3))\\n                plt.title(\"Latent Space\")\\n\\n                plt.subplot(5, 3, 3*i + 3)\\n                plt.imshow(x_reconstruct[i].reshape(28, 28), vmin=0, vmax=1, interpolation=\\'none\\',cmap=plt.get_cmap(\\'gray\\'))\\n                plt.title(\"Reconstruction\")\\n                #plt.colorbar()\\n            plt.tight_layout()\\n'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def weight_variable(shape):\n",
    "    return tf.Variable(tf.truncated_normal(shape, stddev=0.1))\n",
    "\n",
    "def bias_variable(shape):\n",
    "    return tf.Variable(tf.constant(0.1, shape=shape))\n",
    "\n",
    "class VariationalAutoencoder():\n",
    "    def __init__(self, **options ):\n",
    "        self.latent_space_dim = options.get(\"latent_space_dim\")\n",
    "        self.sess = tf.Session()\n",
    "        #print self.latent_space_dim\n",
    "        \n",
    "    #def ___init__(self, data):\n",
    "        #self.data = data\n",
    "        #n = data.shape[0]\n",
    "        #m = data.shape[1]\n",
    "        #self.x = tf.placeholder(tf.float32, [None, m])\n",
    "        #self.y = tf.placeholder(tf.float32, [None, m])\n",
    "    \n",
    "    def fit(self, X):\n",
    "        self.num_samples = X.shape[0]\n",
    "        #self.num_classes = Y.shape[1]\n",
    "        self.num_features = X.shape[1]\n",
    "        self.x = tf.placeholder(tf.float32, [None, self.num_features]) \n",
    "        #self.y = tf.placeholder(tf.float32, [None, self.num_classes])\n",
    "        self.X_train = X\n",
    "        #print self.num_samples\n",
    "        #print self.num_features\n",
    "        #print( self.X_train)\n",
    "        #self.y_train = Y\n",
    "    \n",
    "    def encode(self, X):\n",
    "        with tf.variable_scope(\"encoder\"):\n",
    "            #first hidden_layer\n",
    "            W1 = weight_variable([self.num_features, 500]) \n",
    "            b1 = bias_variable([500])\n",
    "            h1 = tf.nn.tanh( tf.matmul(X,W1) + b1 )\n",
    "            \n",
    "            #second hidden_layer\n",
    "            W2 = weight_variable([500, 500])\n",
    "            b2 = bias_variable([500])\n",
    "            h2 = tf.nn.tanh( tf.matmul(h1, W2) + b2 )\n",
    "            \n",
    "            #mean and sigma layer\n",
    "            W3 = weight_variable([500,self.latent_space_dim])\n",
    "            b3 = bias_variable([self.latent_space_dim])\n",
    "            W_mean = tf.matmul(h2, W3 ) + b3 \n",
    "            \n",
    "            W4 = weight_variable([500,self.latent_space_dim])\n",
    "            b4 = bias_variable([self.latent_space_dim])\n",
    "            W_sigma = tf.matmul(h2,W4) + b4 \n",
    "        return W_mean, W_sigma\n",
    "    \n",
    "    def decode(self,z):\n",
    "        with tf.variable_scope(\"decoder\"):\n",
    "            #first hidden layer\n",
    "            W1 = weight_variable([self.latent_space_dim, 500])\n",
    "            b1 = bias_variable([500])\n",
    "            h1 = tf.nn.tanh(tf.matmul(z, W1) + b1)\n",
    "            \n",
    "            #second hidden layer\n",
    "            W2 = weight_variable([500,500])\n",
    "            b2 = bias_variable([500])\n",
    "            h2 = tf.nn.tanh(tf.matmul(h1, W2) + b2 )\n",
    "            \n",
    "            #reconstruction layer\n",
    "            W3 = weight_variable([500, self.num_features])\n",
    "            b3 = bias_variable([self.num_features])\n",
    "            generated = tf.nn.sigmoid( tf.matmul(h2, W3) + b3 )\n",
    "            \n",
    "        return generated    \n",
    "    \n",
    "    ##cross_entropy(t,o) = -(t * log(o) + (1-t) * log(1-o)) \n",
    "    @staticmethod\n",
    "    def binary_cross_entropy(x, x_reconstructed, offset = 1e-8):\n",
    "        return -tf.reduce_sum( x * tf.log( offset + x_reconstructed ) + \n",
    "                              (1 - x) * tf.log( offset + 1 - x_reconstructed ) , 1)\n",
    "    \n",
    "    @staticmethod\n",
    "    def KL_divergence(z_mean, z_sigma):\n",
    "        return -0.5 * tf.reduce_sum(1 + tf.log(tf.square(z_sigma)) - \n",
    "                                    tf.square(z_sigma) - tf.square(z_mean), 1 ) \n",
    "    \n",
    "    def train(self,x_sample, batch_size = 100, epochs = 20 ):\n",
    "        self.z_mean, self.z_sigma = self.encode(self.x)\n",
    "        noise = tf.random_normal([batch_size, self.latent_space_dim], mean = 0 , stddev = 1, dtype= tf.float32)\n",
    "        z = self.z_mean + self.z_sigma * noise\n",
    "        self.generated = self.decode(z)\n",
    "        #generated_flat = tf.reshape(self.generated, [batch_size, 28*28])\n",
    "        \n",
    "        ##Loss = Reconstruction loss + KL-divergence cost\n",
    "        # -divergence = 1/2 * sum( 1 + log(sigma^2) - sigma^2 - mean^2 )\n",
    "        #divergence_cost = -0.5 * tf.reduce_sum(1 + tf.log(tf.square(self.z_sigma)) - tf.square(self.z_sigma) - tf.square(self.z_mean), 1 ) \n",
    "        divergence_cost = self.KL_divergence(self.z_mean, self.z_sigma)\n",
    "        \n",
    "        # binary cross entropy = -(t * log(o) + (1-t) * log(1-o)) \n",
    "        reconstruction_loss = self.binary_cross_entropy(self.x, self.generated)\n",
    "        #offset = 1e-8\n",
    "        #reconstruction_loss = -tf.reduce_sum( self.x * tf.log( offset + self.generated ) + \n",
    "        #                      (1 - self.x) * tf.log( offset + 1 - self.generated ) , 1)\n",
    "        #print( divergence_cost )\n",
    "        total_loss = tf.reduce_mean(reconstruction_loss + divergence_cost)\n",
    "        train_step = tf.train.AdamOptimizer(learning_rate=0.001).minimize(total_loss)\n",
    "        \n",
    "        #saver = tf.train.Saver()\n",
    "        '''\n",
    "        with tf.Session() as sess:\n",
    "            sess.run(tf.initialize_all_variables())\n",
    "            batches = int(self.num_samples/batch_size)\n",
    "            \n",
    "            for epoch in range(epochs):\n",
    "                avg_cost = 0\n",
    "                avg_divergence = 0\n",
    "                avg_reconstruction = 0\n",
    "                for i in range(batches):\n",
    "                    # Shuffle the data\n",
    "                    #print(\"start:{} end:{}\".format(i * batch_size,i * batch_size + batch_size) )\n",
    "                    x_batch = self.X_train[i * batch_size: i * batch_size + batch_size ][:]\n",
    "                    _, kl_cost, rec_loss, total_cost = sess.run( (train_step, divergence_cost, reconstruction_loss, total_loss ), feed_dict={self.x:x_batch} )\n",
    "                    avg_divergence += np.mean( kl_cost )\n",
    "                    avg_reconstruction += np.mean( rec_loss )\n",
    "                    avg_cost += total_cost #avg_cost += total_cost / self.num_samples * batch_size\n",
    "                avg_reconstruction /= batches\n",
    "                avg_divergence /= batches\n",
    "                avg_cost /= batches\n",
    "                print(\"Epoch: {}, Divergence={}, Reconstruction={}, Cost={}\".format(epoch, avg_divergence, avg_reconstruction, avg_cost))\n",
    "            \n",
    "        \n",
    "            x_reconstruct,z_vals,z_mean_val,z_log_sigma_sq_val = sess.run((self.generated,z, \n",
    "                                                                           self.z_mean, self.z_sigma), \n",
    "                                                                           feed_dict={self.x: x_sample})\n",
    "\n",
    "            plt.figure(figsize=(8, 12))\n",
    "            for i in range(5):\n",
    "                plt.subplot(5, 3, 3*i + 1)\n",
    "                plt.imshow(x_sample[i].reshape(28, 28), vmin=0, vmax=1,  interpolation='none',cmap=plt.get_cmap('gray'))\n",
    "                plt.title(\"Test input\")\n",
    "\n",
    "                #plt.colorbar()\n",
    "                plt.subplot(5, 3, 3*i + 2)\n",
    "                plt.scatter(z_vals[:,0],z_vals[:,1], c='gray', alpha=0.5)\n",
    "                plt.scatter(z_mean_val[i,0],z_mean_val[i,1], c='green', s=64, alpha=0.5)\n",
    "                plt.scatter(z_vals[i,0],z_vals[i,1], c='blue', s=16, alpha=0.5)\n",
    "\n",
    "                plt.xlim((-3,3))\n",
    "                plt.ylim((-3,3))\n",
    "                plt.title(\"Latent Space\")\n",
    "\n",
    "                plt.subplot(5, 3, 3*i + 3)\n",
    "                plt.imshow(x_reconstruct[i].reshape(28, 28), vmin=0, vmax=1, interpolation='none',cmap=plt.get_cmap('gray'))\n",
    "                plt.title(\"Reconstruction\")\n",
    "                #plt.colorbar()\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            #save_path = saver.save(sess, \"model/vae.ckpt\") #Saves the weights (not the graph)\n",
    "            #print(\"Model saved in file: {}\".format(save_path))\n",
    "        '''\n",
    "        self.sess.run(tf.initialize_all_variables())\n",
    "        batches = int(self.num_samples/batch_size)\n",
    "            \n",
    "        for epoch in range(epochs):\n",
    "            avg_cost = 0\n",
    "            avg_divergence = 0\n",
    "            avg_reconstruction = 0\n",
    "            for i in range(batches):\n",
    "                    # Shuffle the data\n",
    "                    #print(\"start:{} end:{}\".format(i * batch_size,i * batch_size + batch_size) )\n",
    "                x_batch = self.X_train[i * batch_size: i * batch_size + batch_size ][:]\n",
    "                _, kl_cost, rec_loss, total_cost = self.sess.run( (train_step, divergence_cost, reconstruction_loss, total_loss ), feed_dict={self.x:x_batch} )\n",
    "                avg_divergence += np.mean( kl_cost )\n",
    "                avg_reconstruction += np.mean( rec_loss )\n",
    "                avg_cost += total_cost #avg_cost += total_cost / self.num_samples * batch_size\n",
    "            avg_reconstruction /= batches\n",
    "            avg_divergence /= batches\n",
    "            avg_cost /= batches\n",
    "            print(\"Epoch: {}, Divergence={}, Reconstruction={}, Cost={}\".format(epoch, avg_divergence, avg_reconstruction, avg_cost))\n",
    "\n",
    "    #x_sample format [1,num_features]\n",
    "    def visualize_generation(self, x_sample):\n",
    "        x_reconstruct = self.sess.run(self.generated, feed_dict={self.x: x_sample})\n",
    "        plt.figure()\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(x_sample.reshape(28, 28), vmin=0, vmax=1,interpolation='none',cmap=plt.get_cmap('gray'))\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(x_reconstruct[0].reshape(28, 28), vmin=0, vmax=1,interpolation='none',cmap=plt.get_cmap('gray'))\n",
    "        \n",
    "'''   \n",
    "    def visualize_generation(self, x_sample):\n",
    "        with tf.Session() as sess:\n",
    "            x_reconstruct,z_vals,z_mean_val,z_log_sigma_sq_val = sess.run((self.generated,self.z, \n",
    "                                                                           self.z_mean, self.z_sigma), \n",
    "                                                                           feed_dict={self.x: x_sample})\n",
    "\n",
    "            plt.figure(figsize=(8, 12))\n",
    "            for i in range(5):\n",
    "                plt.subplot(5, 3, 3*i + 1)\n",
    "                plt.imshow(x_sample[i].reshape(28, 28), vmin=0, vmax=1,  interpolation='none',cmap=plt.get_cmap('gray'))\n",
    "                plt.title(\"Test input\")\n",
    "\n",
    "                #plt.colorbar()\n",
    "                plt.subplot(5, 3, 3*i + 2)\n",
    "                plt.scatter(z_vals[:,0],z_vals[:,1], c='gray', alpha=0.5)\n",
    "                plt.scatter(z_mean_val[i,0],z_mean_val[i,1], c='green', s=64, alpha=0.5)\n",
    "                plt.scatter(z_vals[i,0],z_vals[i,1], c='blue', s=16, alpha=0.5)\n",
    "\n",
    "                plt.xlim((-3,3))\n",
    "                plt.ylim((-3,3))\n",
    "                plt.title(\"Latent Space\")\n",
    "\n",
    "                plt.subplot(5, 3, 3*i + 3)\n",
    "                plt.imshow(x_reconstruct[i].reshape(28, 28), vmin=0, vmax=1, interpolation='none',cmap=plt.get_cmap('gray'))\n",
    "                plt.title(\"Reconstruction\")\n",
    "                #plt.colorbar()\n",
    "            plt.tight_layout()\n",
    "'''        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VAE = VariationalAutoencoder(latent_space_dim = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "VAE.fit(mnist.train.images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Divergence=73.5651754171, Reconstruction=203.966255854, Cost=277.531431691\n",
      "Epoch: 1, Divergence=76.1387107676, Reconstruction=183.460733393, Cost=259.59944261\n",
      "Epoch: 2, Divergence=102.075419523, Reconstruction=184.795110224, Cost=286.870528287\n",
      "Epoch: 3, Divergence=37.5375278161, Reconstruction=171.248760348, Cost=208.786286788\n",
      "Epoch: 4, Divergence=35.7788398222, Reconstruction=164.965698436, Cost=200.744537881\n",
      "Epoch: 5, Divergence=41.9762366191, Reconstruction=164.099601912, Cost=206.075838762\n",
      "Epoch: 6, Divergence=13.4775243829, Reconstruction=153.252354237, Cost=166.72987854\n",
      "Epoch: 7, Divergence=37.3962911883, Reconstruction=165.49715443, Cost=202.893445185\n",
      "Epoch: 8, Divergence=13.7593872781, Reconstruction=146.945507147, Cost=160.704893438\n",
      "Epoch: 9, Divergence=14.7173961015, Reconstruction=144.256509677, Cost=158.973905251\n",
      "Epoch: 10, Divergence=27.0358130576, Reconstruction=144.924583074, Cost=171.960396507\n",
      "Epoch: 11, Divergence=11.9912761359, Reconstruction=129.883024667, Cost=141.87430155\n",
      "Epoch: 12, Divergence=11.9960361637, Reconstruction=125.331961628, Cost=137.327997742\n",
      "Epoch: 13, Divergence=27.5257117011, Reconstruction=142.117222387, Cost=169.642936193\n",
      "Epoch: 14, Divergence=14.6394778009, Reconstruction=149.904160115, Cost=164.543637779\n",
      "Epoch: 15, Divergence=23.0150585573, Reconstruction=141.976786874, Cost=164.991844288\n",
      "Epoch: 16, Divergence=12.2589996806, Reconstruction=125.886738573, Cost=138.145738109\n",
      "Epoch: 17, Divergence=16.2749406416, Reconstruction=127.024352126, Cost=143.299292436\n",
      "Epoch: 18, Divergence=14.5354255763, Reconstruction=129.749269062, Cost=144.284694699\n",
      "Epoch: 19, Divergence=13.00654545, Reconstruction=116.759081587, Cost=129.765627303\n"
     ]
    }
   ],
   "source": [
    "x_sample = mnist.test.next_batch(100)[0]\n",
    "VAE.train(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW0AAAC2CAYAAAASj9x6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAE7JJREFUeJzt3XmMVVW2x/HfUkFEFHAAZCxxngkO0dDGNj1EnxoN4ovB\nxDEdYtQ28Y+n3YmiRk1r1MSYaOKEaMD22YnCX4IEg6FFxQYEUZAXKIXGQuKAFiqD7PdHXduSvQ51\nqu45t86+fD9Jxap19737HO6q5am79z7bQggCAKRhn94+AABAfhRtAEgIRRsAEkLRBoCEULQBICEU\nbQBISF1F28wuMLNVZvaJmd1e1EEBvY3cRlVZT+dpm9k+kj6R9DtJGyUtlnRlCGFVcYcHNB65jSrb\nr47nniVpTQjhU0kys79LulTSrxLbzFi9g1KFEKzglyS3UQlebtfz8cgISes7/byhFgNSR26jV513\n3nmZjzEQCQAV09ramvlYPUX735JGd/p5ZC0GpI7cRq9qaWnJfKyeor1Y0tFmNsbM+kq6UtLsOl4P\nqApyG5XV44HIEMJPZnazpLnqKP7PhhA+LuzIgF5CbqPK6pk9ohDC65KOK+hYgMogt1FVDEQCQEIo\n2gCQEIo2ACSEog0ACaFoA0BCKNoAkBCKNgAkhKINAAmhaANAQupaEQkA9dhnH/+60SzfLdJ37drl\nxnu6uUsKuNIGgIRQtAEgIRRtAEgIRRsAEsJAZMH233//KPbUU0+5bU866aQo5g2g3Hvvve7z33jj\njSj2008/uW137NjhxoE8sgYM+/btG8VGjhzptj3uuPhOtyeccILbdt99941imzdvjmIbN250n+/F\nN2zY4LbdsmVLFMv6PaoCrrQBICEUbQBICEUbABJS12faZtYqaYukXZJ2hBDOKuKggN5GbqOq6h2I\n3CXptyGEr4s4GKBCyG1UUr1F27SXfsQybNgwN37DDTdEscmTJ9fV14wZM9z40qVLo9j06dPdts8/\n/3wUy1oCDEl7QW5nzQjp169fFDvssMPctmeffXYUmzhxotv2mGOOiWKHHHKI29bLze3bt0exr776\nyn3+O++8E8VmzZrltvV+j9rb2922VVgeX29SBklvmNliM/tTEQcEVAS5jUqq90p7QgjhczM7XB0J\n/nEIYWERBwb0MnIblVTXlXYI4fPafzdLelUSgzVoCuQ2elNra2vmYz0u2mbW38wG1L4/UNIfJX3Y\n09cDqoLcRm9raWnJfKyej0eGSnrVzELtdWaEEObW8XqVNWTIkCj22muvuW1PP/30KJZ1b2BvUOOV\nV17J/fxJkyZFsXPOOcdt6y0Lfvrpp922aL7c9gYd99vP//UfPHhwFJswYYLbdsqUKVEsa2m6t+R9\n586dblvvtgveLSK8mCSdeuqpUcy77YOU3oB8j4t2CGGdpHEFHgtQCeQ2qqyppzQBQLOhaANAQija\nAJAQijYAJIRNEHJ46KGHopg3S0TyZ4S89NJLbtv7778/iq1Zsyb3cd1zzz1RbP78+W7bBx54IIot\nX77cbfvuu+/mPgakwZuBdPDBB7ttvc05LrnkErettzTdmyUiSd99910UW79+vdt269atUSxrKb3n\niy++iGJZG4FUYWl6d3ClDQAJoWgDQEIo2gCQEIo2ACSEgcgcvvzyy9xtv//++yh29dVXF3k4/7Fq\n1aoolrVU17un98MPP+y2Pffcc+s7MPQqb9DRu41B1j3hvVshnHzyyW5bb9DR2zVdkl5//fUotmjR\nIrftiBEjch3X8OHD3ed7x9DW1ua29XZer/LgJFfaAJAQijYAJISiDQAJoWgDQEIo2gCQEGaP5HD3\n3XdHsdGjR7ttL7zwwig2duxYt+3atWvrOi7Paaedlrtt1uYKSJv3vvbp0yeKZe3G7u2a4s0+kfxZ\nGgsWLHDbzp49O4plzejwZqUcfvjhUSxrN3cvnnW+Xrw7G5c0GlfaAJAQijYAJISiDQAJ6bJom9mz\nZrbJzJZ3ig02s7lmttrM5pjZwHIPEygeuY0U5RmInCbpcUkvdIrdIWleCOEhM7td0l9qsabk3Qf4\nvvvuc9uef/75UWzGjBluW2+H6+7sDN2vX78oljVg5Mlq6w3MpLZjdU57TW57A2v9+/d323rvddat\nHNatWxfFVqxY4bb98ccfo9igQYPctmeffXYU8wb0s3aU935ns3K4CoOL3dHllXYIYaGkr3cLXypp\neu376ZIuK/i4gNKR20hRTz/THhJC2CRJIYQ2SUOKOySgV5HbqLSiBiLT+vsCyI/cRsO1trZmPtbT\nor3JzIZKkpkNkxRvyAakidxGr/MWOP0s74pIq339bLakayU9KOkaSbN6dmjp+uCDD9z4RRddFMUW\nLlzotp04cWIUe/PNN6NY1koubwPeUaNGuW093gauknTCCSdEsZUrV+Z+3cQ0XW57A2s7d+6MYu3t\n7e7zV69eHcWyBvG81x0zZozb9qCDDopiWZv1er9H3kbE3v3rJX+l5rfffuu29e6nXWV5pvzNlPS2\npGPN7DMzu07S3yT9wcxWS/pd7WcgKeQ2UtTllXYIId7ypMPvCz4WoKHIbaSIFZEAkBCKNgAkhKIN\nAAnhftoFe//996PYk08+6bZ9/PHHo9g333wTxbKWEHdnpsj27duj2JQpU9y2TTxTZK/gzR7xZn94\nuSb5M6Oybnng7dI+cKB/u5ajjjoq1/Mlf3m7t2T96693X9Da4e23345iX331lduW3dgBAKWhaANA\nQijaAJAQijYAJISByIJ5gxqLFy922954441RzFvWe8wxx+TuP2sA5frrr49iL7/8cu7XRdq8vNix\nY4fb1ttsd82aNW7bwYMHR7FTTjnFbetttpu1Ma936wZvMD3rxkreptnbtm1z21Z50NHDlTYAJISi\nDQAJoWgDQEIo2gCQEIo2ACSE2SMFO/7446PYtGnTcj/f2zXbi0n+zepvueUWt+28efNyHwPS5uWL\nNxvD28BA8jcQyMrBrI00PN4mBn369HHberOwvNs5zJ8/333+li1bothesxs7AKA6KNoAkBCKNgAk\nJM8ekc+a2SYzW94pNtXMNpjZktrXBeUeJlA8chspyjMQOU3S45Je2C3+aAjh0eIPKQ1XXXWVG3/q\nqafqel1vUCRroOS7776LYuvXr6+r/73MXpPb3kBk1iCgF/eWq0v+bReGDBnitj3wwAP3dIi/4g0k\nLly4MIp596+XpB9//DF3X6np8ko7hLBQknencX84GUgEuY0U1fOZ9s1mtszMnjEzf6sKIE3kNiqr\np0X7CUljQwjjJLVJaqo/JbFXI7fR67LuXij1sGiHEDaHXz5ofVrSmT15HaBqyG1UQUtLS+ZjeYu2\nqdPnfGY2rNNjEyV92JMDAyqA3EZSupw9YmYzJf1W0qFm9pmkqZLON7NxknZJapXkb+vdJLzR8KlT\np7pt+/btm/t1vVkhH330Ua6YJE2aNCmKvfXWW27bMWPGRLFmHmHPI/Xczlpa7u1afuihh0Yxb+aH\nJA0bNiyKTZgwwW17+umnR7GDDjrIbev9bmRtTOAtWf/kk0+iWNYO696S9awd5bszY6sKuizaIYTJ\nTjj/zTSAiiK3kSJWRAJAQijaAJAQijYAJIT7aecwduzYKHbkkUe6bb3BoaxBjbvuuiuKPfLII1Fs\n1KhR7vOvuOKKKJa1u/VNN92Uqy+kI2sg0hsI9AYMx40b5z5/4MB4PdEZZ5zhth0+fHgU83ZNl/yB\n76xz8AYNvfMaMGCA+3xv0DPr99C7d3eVByK50gaAhFC0ASAhFG0ASAhFGwASwkBkDt4KsawBlO5Y\ntGhRFPMGcYoYFMm6dzLS4OVb1go/b8Du6KOPjmJnnunfVsVbAZx1L+xvv/02imWtcvReo3///m5b\nbyDRW9WZ9W/gDVB6A46Sf6/xLFVYPcmVNgAkhKINAAmhaANAQijaAJAQijYAJITZIzl4y8WzeCPJ\na9euddsuWbIkit15551RbE+7WKC5dGdZd3dmBHlthw4d6rYdNGhQFPvhhx/ctt9//30U8+5lLUn9\n+vWLYln3n897P2zvWCV/RkjWLA+vbdY5VAFX2gCQEIo2ACSEog0ACemyaJvZSDObb2YrzWyFmf25\nFh9sZnPNbLWZzTGz+H6OQIWR20hRnoHInZJuCyEsM7MBkv5lZnMlXSdpXgjhITO7XdJfJN1R4rEm\nK2sD3WnT4u0IL7744ijWnQ1Jd+7c6bZ977339nSIe6tkctvLgQMOOMBt6y1jP+KII6KYNzCYJWup\nt/caWUvevQ2Hs/LV+51pa2vLFZP8JetZ59CdZehVuM92l1faIYS2EMKy2vftkj6WNFLSpZKm15pN\nl3RZWQcJlIHcRoq69Zm2mbVIGifpHUlDQwibpI7klxTfZQZIBLmNVOQu2rU/H/8h6dbaVcnufyf0\n/t8NQA+Q26ia1tbWzMdyFW0z208dSf1iCGFWLbzJzIbWHh8m6Yv6DhNoPHIbVbSnBXV5r7Sfk/RR\nCOGxTrHZkq6tfX+NpFm7PwlIALmNpHQ5e8TMJki6StIKM1uqjj8V/yrpQUn/a2bXS/pU0n+XeaC9\n6csvv8zd1luGfOKJJ7pts+J5bd26NYpdc801btv58+fX1VczSim3vWXoWbM0vKu00aNHRzFvNofk\nz7LYf//93bbeMWQtAfdmhGzcuNFtu3Tp0ijm5fCGDRvc57e3t0exrJkqVdjYoDu6LNohhH9K8uec\nSb8v9nCAxiG3kSJWRAJAQijaAJAQijYAJIT7aefwxBNPRLHJkye7bb37+2bdI9kb7Fi3bl0Ue/LJ\nJ93nv/nmm1Fs2bJlblukIWsAbMeOHVEsa1n2wIHxrVK8ZfBZA5lZy+M93n22t2zZ4rb98MMPo9ic\nOXPctitXroxi3qCldz9vSdq+fXsUy9qN3Rs4rfJAJFfaAJAQijYAJISiDQAJoWgDQEIo2gCQEGaP\n5LBq1aooNmnSJLft5ZdfHsWydnO///77o9jMmTOjWHeW0aM5ebMhsjYAWLRoURTzlsFnzbwYNWpU\nFMuaAeUtI1++fLnbdt68eVFs/fr1bltvBor3b5A1y8ObKZLVtsozRTxcaQNAQijaAJAQijYAJISi\nDQAJsbI/hDeztD7lR3JCCP4oWcmqmtve8nZvINLbtV3y752dNRDpLWP37mUt+Uvxm2VwsGjnnXee\nFixY4OY2V9oAkBCKNgAkhKINAAnpsmib2Ugzm29mK81shZndUotPNbMNZrak9nVB+YcLFIfcRory\nrIjcKem2EMIyMxsg6V9m9kbtsUdDCI+Wd3hAqZoyt737Q2/bti1XDNWXZ2PfNkltte/bzexjSSNq\nD/fKqD1QBHIbKerWZ9pm1iJpnKR3a6GbzWyZmT1jZvF2GUAiyG2kInfRrv35+A9Jt4YQ2iU9IWls\nCGGcOq5WkvxTEiC3UTWtra2Zj+Uq2ma2nzqS+sUQwixJCiFsDr/MgH9a0pn1HSbQeOQ2qqilpSXz\nsbxX2s9J+iiE8NjPATMb1unxiZLiXTuB6iO3kZQuByLNbIKkqyStMLOlkoKkv0qabGbjJO2S1Cpp\nSonHCRSO3EaK8swe+aekfZ2HXi/+cIDGIbeRIlZEAkBCKNoAkBCKNgAkhKINAAmhaANAQijaAJAQ\nijYAJISiDQAJyXM/7bqNHz9ekrRx40YNHz68EV3SV2J99bS/JUuWlHQ0+YwfP573hL4K7+vYY4/V\nggUL3MfYjR3JYzd2NCsvt0sv2gCA4vCZNgAkhKINAAmhaANAQhpStM3sAjNbZWafmNntJffVamYf\nmNlSM3uvhNd/1sw2mdnyTrHBZjbXzFab2Zyi9hTM6GuqmW0wsyW1rwsK6mukmc03s5VmtsLM/lyL\nF35uTl+31OKlnFuZmiW3G5nXe+iv8Pe/kXmd0V/xuR1CKPVLHf9j+D9JYyT1kbRM0vEl9rdW0uAS\nX/836tgAdnmn2IOS/qf2/e2S/lZiX1Ml3VbCeQ2TNK72/QBJqyUdX8a57aGvUs6txFxomtxuZF7v\nob/C3/9G5nUX/RV2bo240j5L0poQwqchhB2S/i7p0hL7M5X4F0QIYaGkr3cLXyppeu376ZIuK7Ev\nqeMcCxVCaAshLKt93y7pY0kjVcK5ZfQ1ovZwr0zf66Gmye1G5vUe+pMKfv8bmdd76K/Q3G5E0R4h\naX2nnzfol5MoQ5D0hpktNrM/ldhPZ0NCCJukjjdN0pCS+7vZzJaZ2TNF/sn6MzNrUcdV0DuShpZ5\nbp36ercWKvXcCtbsud3ovJZKfP8bmde79VdobjfjQOSEEMJ4Sf8l6SYz+00vHEOZk9+fkDQ2hDBO\nUpukR4t8cTMboI7dyW+tXSnsfi6FnZvTV6nn1gR6O7fLXtRR2vvfyLzO6K+wc2tE0f63pNGdfh5Z\ni5UihPB57b+bJb2qjj9hy7bJzIZK/9nJ+4uyOgohbA61D8wkPS3pzKJe28z2U0eivRhCmFULl3Ju\nXl9lnltJmj23G5bXUnnvfyPzOqu/Is+tEUV7saSjzWyMmfWVdKWk2WV0ZGb9a/+Hk5kdKOmPkj4s\noyv9+vOp2ZKurX1/jaRZuz+hqL5qCfaziSr2/J6T9FEI4bFOsbLOLeqr5HMrQ7PldiPzOuqvxPe/\nkXnt9lfouRU5UruHEdUL1DGKukbSHSX2c6Q6RvCXSlpRRl+SZkraKGmbpM8kXSdpsKR5tXOcK2lQ\niX29IGl57TxfU8dnc0X0NUHST53+/ZbU3rdDij63PfRVyrmV+dUsud3IvN5Df4W//43M6y76K+zc\nuPcIACSkGQciAaBpUbQBICEUbQBICEUbABJC0QaAhFC0ASAhFG0ASMj/A5fxJBJk0fZqAAAAAElF\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xe71ea50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#d = np.zeros([100,2],dtype='float32')\n",
    "#d[0,] = [1,2]\n",
    "#x_sample[0:1].shape\n",
    "#plt.figure()\n",
    "#plt.subplot(1,2,1)\n",
    "#plt.imshow(x_sample[1].reshape(28, 28), vmin=0, vmax=1,interpolation='none',cmap=plt.get_cmap('gray'))\n",
    "#plt.subplot(1,2,2)\n",
    "image_id = 9\n",
    "VAE.visualize_generation(x_sample[image_id:image_id + 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "x_sample = mnist.test.next_batch(10)[0]\n",
    "#print(x_sample[0,:])\n",
    "#VAE.visualize_generation(x_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "check_point_file = \"model/vae.ckpt\"\n",
    "saver = tf.train.Saver()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, check_point_file)\n",
    "    print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
